## TODO:

* https://arxiv.org/abs/2210.17323 (GPTQ quantized)
* https://bair.berkeley.edu/blog/2023/04/03/koala/
* https://chat.lmsys.org/
* https://github.com/EleutherAI/lm-evaluation-harness
* https://github.com/ZrrSkywalker/LLaMA-Adapter
* https://github.com/eugeneyan/open-llms
* https://github.com/gururise/AlpacaDataCleaned 
* https://github.com/imaurer/awesome-decentralized-llm
* https://github.com/lm-sys/FastChat#vicuna-weights
* https://github.com/young-geng/EasyLM
* https://huggingface.co/OpenAssistant (from open-llms: training set and fine tuned models based on pythia and Llama)
* https://huggingface.co/google/flan-t5-xxl (from open-llms)
* https://huggingface.co/google/flan-ul2 (from open-llms)
* https://huggingface.co/young-geng/koala
* https://www.semianalysis.com/p/google-we-have-no-moat-and-neither
* huggingface/datasets: h2oai/h2ogpt-* (instruction tuning datasets)
* huggingface/datasets: https://huggingface.co/datasets/togethercomputer/RedPajama-Data-1T
* huggingface/transformers: CarperAI/stable-vicuna-13b-delta (depends on llama-13b)
* huggingface/transformers: EleutherAI/pythia-XXX  (from open-llms, open source alternative to Llama?)
* huggingface/transformers: bigscience/bloom (176B) 
* huggingface/transformers: bigscience/bloom-1b1 
* huggingface/transformers: bigscience/bloom-1b7 
* huggingface/transformers: bigscience/bloom-3b 
* huggingface/transformers: bigscience/bloom-7b1 
* huggingface/transformers: bigscience/bloomz 
* huggingface/transformers: bigscience/bloomz-1b1 
* huggingface/transformers: bigscience/bloomz-1b7 
* huggingface/transformers: bigscience/bloomz-3b 
* huggingface/transformers: bigscience/bloomz-560m
* huggingface/transformers: bigscience/bloomz-7b1 
* huggingface/transformers: bigscience/bloomz-7b1-mt 
* huggingface/transformers: bigscience/bloomz-mt 
* huggingface/transformers: bigscience/mt0-base 
* huggingface/transformers: bigscience/mt0-large 
* huggingface/transformers: bigscience/mt0-small 
* huggingface/transformers: bigscience/mt0-xl 
* huggingface/transformers: bigscience/mt0-xxl 
* huggingface/transformers: bigscience/mt0-xxl-mt 
* huggingface/transformers: decapoda-research/llama-13b-hf-int4
* huggingface/transformers: decapoda-research/llama-30b-hf-int4
* huggingface/transformers: decapoda-research/llama-65b-hf
* huggingface/transformers: decapoda-research/llama-65b-hf-int4
* huggingface/transformers: decapoda-research/llama-7b-hf-int4
* huggingface/transformers: decapoda-research/llama-7b-hf-int8
* huggingface/transformers: decapoda-research/llama-smallint-pt
* huggingface/transformers: facebook/opt-1.3b 
* huggingface/transformers: facebook/opt-125m 
* huggingface/transformers: facebook/opt-13b 
* huggingface/transformers: facebook/opt-2.7b 
* huggingface/transformers: facebook/opt-30b 
* huggingface/transformers: facebook/opt-350m 
* huggingface/transformers: facebook/opt-6.7b 
* huggingface/transformers: facebook/opt-66b 
* huggingface/transformers: facebook/opt-iml-1.3b 
* huggingface/transformers: facebook/opt-iml-30b 
* huggingface/transformers: facebook/opt-iml-max-1.3b 
* huggingface/transformers: facebook/opt-iml-max-30b 
* huggingface/transformers: h2oai/h2ogpt-* (from open-llms)
* huggingface/transformers: huggyllama/llama-65b 
* huggingface/transformers: lmsys/vicuna-13b-delta-v0 
* huggingface/transformers: lmsys/vicuna-7b-delta-v0  
* huggingface/transformers: mosaicml/mosaic-bert-base
* huggingface/transformers: mosaicml/mosaic-bert-base-seqlen-1024
* huggingface/transformers: mosaicml/mosaic-bert-base-seqlen-2048
* huggingface/transformers: mosaicml/mosaic-bert-base-seqlen-256
* huggingface/transformers: mosaicml/mosaic-bert-base-seqlen-512
* huggingface/transformers: nomic-ai/gpt4all-lora-epoch-3 
* huggingface/transformers: samwit/alpaca7B-lora  (original alpaca: gururise refers to it but don't know how to download)
* huggingface/transformers: tloen/alpaca-lora-7b  (trained with yahma/alpaca-cleaned 2023-03-26: gururise refers to it but don't know how to download)
