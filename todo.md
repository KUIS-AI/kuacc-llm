## TODO:

* == stabilityai/stablelm-base-alpha-3b
* == pythainlp/wangchanglm-7.5B-sft-en-sharded
* == stabilityai/stablelm-tuned-alpha-3b
* == hakurei/instruct-12b
* == lamini/instruct-tuned-3b
* == bigscience/bloomz-3b
* == vicgalle/gpt2-alpaca-gpt4
* == cerebras/Cerebras-GPT-111M
* == distilgpt2
* == gpt2
* == facebook/opt-125m
* == facebook/opt-350m
* == cerebras/Cerebras-GPT-1.3B
* == gpt2-medium
* == gpt2-large
* == aisquared/dlite-v2-774m
* == gpt2-xl
* == facebook/opt-1.3b
* == stabilityai/stablelm-tuned-alpha-7b
* == Salesforce/codegen-16B-multi
* == HuggingFaceH4/starchat-alpha
* == databricks/dolly-v2-3b
* == togethercomputer/RedPajama-INCITE-Base-3B-v1
* == KoboldAI/OPT-13B-Nerybus-Mix
* == facebook/opt-13b
* == EleutherAI/gpt-j-6b
* == databricks/dolly-v2-7b
* == Pirr/pythia-13b-deduped-green_devil
* == databricks/dolly-v2-12b
* == OpenAssistant/oasst-sft-4-pythia-12b-epoch-3.5
* == togethercomputer/RedPajama-INCITE-Base-7B-v0.1
* == EleutherAI/gpt-neox-20b
* == nomic-ai/gpt4all-j
* == chainyo/alpaca-lora-7b
* == wordcab/llama-natural-instructions-13b
* == eachadea/vicuna-7b-1.1
* == CarperAI/stable-vicuna-13b-delta
* == eachadea/vicuna-13b
* == chavinlo/gpt4-x-alpaca
* == TheBloke/vicuna-13B-1.1-HF
* == TheBloke/dromedary-65b-lora-HF
* == Aeala/GPT4-x-AlpacaDente2-30b
* == digitous/Alpacino30b
* == MetaIX/GPT4-X-Alpasta-30b

* https://arxiv.org/abs/2210.17323 (GPTQ quantized)
* https://bair.berkeley.edu/blog/2023/04/03/koala/
* https://chat.lmsys.org/
* https://github.com/EleutherAI/lm-evaluation-harness
* https://github.com/ZrrSkywalker/LLaMA-Adapter
* https://github.com/eugeneyan/open-llms
* https://github.com/gururise/AlpacaDataCleaned 
* https://github.com/imaurer/awesome-decentralized-llm
* https://github.com/lm-sys/FastChat#vicuna-weights
* https://github.com/young-geng/EasyLM
* https://huggingface.co/OpenAssistant (from open-llms: training set and fine tuned models based on pythia and Llama)
* https://huggingface.co/google/flan-t5-xxl (from open-llms)
* https://huggingface.co/google/flan-ul2 (from open-llms)
* https://huggingface.co/young-geng/koala
* https://www.semianalysis.com/p/google-we-have-no-moat-and-neither
* huggingface/datasets: h2oai/h2ogpt-* (instruction tuning datasets)
* huggingface/datasets: https://huggingface.co/datasets/togethercomputer/RedPajama-Data-1T
* huggingface/transformers: CarperAI/stable-vicuna-13b-delta (depends on llama-13b)
* huggingface/transformers: EleutherAI/pythia-XXX  (from open-llms, open source alternative to Llama?)
* huggingface/transformers: bigscience/bloom (176B) 
* huggingface/transformers: bigscience/bloom-1b1 
* huggingface/transformers: bigscience/bloom-1b7 
* huggingface/transformers: bigscience/bloom-3b 
* huggingface/transformers: bigscience/bloom-7b1 
* huggingface/transformers: bigscience/bloomz 
* huggingface/transformers: bigscience/bloomz-1b1 
* huggingface/transformers: bigscience/bloomz-1b7 
* huggingface/transformers: bigscience/bloomz-3b 
* huggingface/transformers: bigscience/bloomz-560m
* huggingface/transformers: bigscience/bloomz-7b1 
* huggingface/transformers: bigscience/bloomz-7b1-mt 
* huggingface/transformers: bigscience/bloomz-mt 
* huggingface/transformers: bigscience/mt0-base 
* huggingface/transformers: bigscience/mt0-large 
* huggingface/transformers: bigscience/mt0-small 
* huggingface/transformers: bigscience/mt0-xl 
* huggingface/transformers: bigscience/mt0-xxl 
* huggingface/transformers: bigscience/mt0-xxl-mt 
* huggingface/transformers: decapoda-research/llama-13b-hf-int4
* huggingface/transformers: decapoda-research/llama-30b-hf-int4
* huggingface/transformers: decapoda-research/llama-65b-hf
* huggingface/transformers: decapoda-research/llama-65b-hf-int4
* huggingface/transformers: decapoda-research/llama-7b-hf-int4
* huggingface/transformers: decapoda-research/llama-7b-hf-int8
* huggingface/transformers: decapoda-research/llama-smallint-pt
* huggingface/transformers: facebook/opt-1.3b 
* huggingface/transformers: facebook/opt-125m 
* huggingface/transformers: facebook/opt-13b 
* huggingface/transformers: facebook/opt-2.7b 
* huggingface/transformers: facebook/opt-30b 
* huggingface/transformers: facebook/opt-350m 
* huggingface/transformers: facebook/opt-6.7b 
* huggingface/transformers: facebook/opt-66b 
* huggingface/transformers: facebook/opt-iml-1.3b 
* huggingface/transformers: facebook/opt-iml-30b 
* huggingface/transformers: facebook/opt-iml-max-1.3b 
* huggingface/transformers: facebook/opt-iml-max-30b 
* huggingface/transformers: h2oai/h2ogpt-* (from open-llms)
* huggingface/transformers: huggyllama/llama-65b 
* huggingface/transformers: lmsys/vicuna-13b-delta-v0 
* huggingface/transformers: lmsys/vicuna-7b-delta-v0  
* huggingface/transformers: mosaicml/mosaic-bert-base
* huggingface/transformers: mosaicml/mosaic-bert-base-seqlen-1024
* huggingface/transformers: mosaicml/mosaic-bert-base-seqlen-2048
* huggingface/transformers: mosaicml/mosaic-bert-base-seqlen-256
* huggingface/transformers: mosaicml/mosaic-bert-base-seqlen-512
* huggingface/transformers: nomic-ai/gpt4all-lora-epoch-3 
* huggingface/transformers: samwit/alpaca7B-lora  (original alpaca: gururise refers to it but don't know how to download)
* huggingface/transformers: tloen/alpaca-lora-7b  (trained with yahma/alpaca-cleaned 2023-03-26: gururise refers to it but don't know how to download)
* Open-Orca/FLAN
* Open-Orca/OpenOrca
* garage-bAInd/Open-Platypus
